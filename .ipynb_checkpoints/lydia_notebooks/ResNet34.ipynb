{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/qubvel/classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from classification_models.tfkeras import Classifiers\n",
    "VGG16, preprocess_input = Classifiers.get('vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../../bttai-ajl-2025/train/train\"\n",
    "base_test_dir = \"../../bttai-ajl-2025/train/train\"\n",
    "train_csv_path = \"../../bttai-ajl-2025/train.csv\"\n",
    "test_csv_path = \"../../bttai-ajl-2025/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Data \n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Add .jpg extension to md5hash column to reference the file_name\n",
    "train_df['md5hash'] = train_df['md5hash'].astype(str) + '.jpg'\n",
    "test_df['md5hash'] = test_df['md5hash'].astype(str) + '.jpg'\n",
    "\n",
    "# Combine label and md5hash to form the correct path\n",
    "train_df['file_path'] = train_df['label'] + '/' + train_df['md5hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Function to check if image files exist\n",
    "def check_image_paths(df, base_dir):\n",
    "    missing_files = []\n",
    "    existing_files = []\n",
    "    \n",
    "    for file_path in df['file_path']:\n",
    "        full_path = os.path.join(base_dir, file_path)\n",
    "        if not os.path.exists(full_path):\n",
    "            missing_files.append(full_path)\n",
    "        else:\n",
    "            existing_files.append(full_path)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nTotal Missing Files: {len(missing_files)}\")\n",
    "    if missing_files:\n",
    "        print(\"‚ö†Ô∏è First 5 Missing Files for Reference:\")\n",
    "        print(missing_files[:5])\n",
    "\n",
    "    print(f\"\\nTotal Existing Files: {len(existing_files)}\")\n",
    "    if existing_files:\n",
    "        print(\"‚úÖ First 5 Existing Files for Reference:\")\n",
    "        print(existing_files[:5])\n",
    "\n",
    "    return missing_files\n",
    "\n",
    "# Run the file existence check\n",
    "missing_train_files = check_image_paths(train_df, base_dir)\n",
    "\n",
    "# Print sample data\n",
    "print(\"\\nTrain Data Sample:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Data Sample:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "num_skipped = 0\n",
    "\n",
    "for root, _, files in os.walk(base_dir):\n",
    "    for fname in files:\n",
    "        fpath = os.path.join(root, fname)\n",
    "        \n",
    "        # Check if the file is a JPEG (you can extend this check to other formats if needed)\n",
    "        if fname.lower().endswith((\".jpg\", \".jpeg\")):\n",
    "            # print(f\"Checking: {fpath}\")\n",
    "            \n",
    "            try:\n",
    "                with open(fpath, \"rb\") as fobj:\n",
    "                    # Read the first 10 bytes to check for the JFIF marker\n",
    "                    header = fobj.read(10)\n",
    "                    is_jfif = b\"JFIF\" in header\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {fpath}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if not is_jfif:\n",
    "                num_skipped += 1\n",
    "                train_df.drop(train_df.index[train_df['md5hash'] == fname])\n",
    "                # print(f\"Removed corrupted image: {fpath}\")\n",
    "\n",
    "print(f\"Total corrupted images removed: {num_skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y=train_df['label'], order=train_df['label'].value_counts().index)\n",
    "\n",
    "plt.xlabel(\"Number of Images\")\n",
    "plt.ylabel(\"Class Labels\")\n",
    "plt.title(\"Label Distribution in Training Data\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Calculate counts per class\n",
    "class_counts = train_df['label'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Define a threshold (e.g. classes with fewer than 100 samples are underrepresented)\n",
    "threshold = 100\n",
    "underrepresented_classes = class_counts[class_counts < threshold].index.tolist()\n",
    "\n",
    "print(\"Underrepresented classes:\", underrepresented_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "duplicate_counts = train_df['md5hash'].duplicated().sum()\n",
    "\n",
    "print(f\"üîç Duplicate Images Found: {duplicate_counts}\")\n",
    "if duplicate_counts > 0:\n",
    "    print(train_df[train_df['md5hash'].duplicated(keep=False)].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = train_df.isnull().sum()\n",
    "\n",
    "print(\"üîç Missing Values per Column:\\n\", missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check if image files exist\n",
    "missing_files = []\n",
    "for file_path in train_df['file_path']:\n",
    "    full_path = os.path.join(base_dir, file_path)\n",
    "    if not os.path.exists(full_path):\n",
    "        missing_files.append(full_path)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nüîç Total Missing Images: {len(missing_files)}\")\n",
    "if missing_files:\n",
    "    print(\"‚ö†Ô∏è First 5 Missing Images for Reference:\")\n",
    "    print(missing_files[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['label'])  # Features (excluding the label)\n",
    "y_train = train_df['label']  # Target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check `qc` column type\n",
    "print(\"üîç QC Column Data Type:\", X_train['qc'].dtype)\n",
    "\n",
    "# Plot distribution of existing `qc` values (ignoring NaNs)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(X_train['qc'].dropna(), bins=20, kde=True)\n",
    "plt.title(\"Distribution of QC Column (Without NaNs)\")\n",
    "plt.xlabel(\"QC Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def extract_qc_number(qc_value):\n",
    "    if pd.isnull(qc_value):\n",
    "        return None  # Keep NaN values\n",
    "    return int(qc_value.split()[0])  # Extract numeric part (before space)\n",
    "\n",
    "# Apply the function\n",
    "X_train['qc'] = X_train['qc'].apply(extract_qc_number) # Now the qc only holds numbers [1-5] and nan\n",
    "\n",
    "# Print unique values to verify conversion\n",
    "print(\"‚úÖ Unique QC Numeric Values:\", X_train['qc'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new column `sample_weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qc_to_weight(qc_value):\n",
    "    \"\"\"Assigns sample weights based on QC value.\"\"\"\n",
    "    if pd.isnull(qc_value):\n",
    "        # Missing QC\n",
    "        return 0.1\n",
    "    elif qc_value == 1:\n",
    "        # Diagnostic\n",
    "        return 1.0\n",
    "    elif qc_value == 5:\n",
    "        # Potentially diagnostic\n",
    "        return 0.8\n",
    "    elif qc_value == 2:\n",
    "        # Characteristic\n",
    "        return 0.5\n",
    "    elif qc_value == 3:\n",
    "        # Wrongly labeled\n",
    "        return 0.2\n",
    "    elif qc_value == 4:\n",
    "        # Undecided\n",
    "        return 0.3\n",
    "    else:\n",
    "        # Fallback case if there's an unexpected QC value\n",
    "        return 0.0\n",
    "\n",
    "# Applying the function to create a sample_weight column:\n",
    "X_train['sample_weight'] = X_train['qc'].apply(qc_to_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(X_train['sample_weight'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Visualize the numeric QC distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='qc', data=X_train)\n",
    "plt.title(\"Distribution of Numeric QC Values\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize sample_weight distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='sample_weight', data=X_train)\n",
    "plt.title(\"Distribution of Sample Weights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train.drop('qc', axis=1, inplace=True)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check `sample_weight` column type\n",
    "print(\"üîç QC Column Data Type:\", X_train['sample_weight'].dtype)\n",
    "\n",
    "# Plot distribution of existing `qc` values (ignoring NaNs)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(X_train['sample_weight'].dropna(), bins=20, kde=True)\n",
    "plt.title(\"Distribution of sample_weight Column (0.2 is missing value)\")\n",
    "plt.xlabel(\"Sample Weight Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 1) Label encode y_train (which is currently string labels)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)  # array of ints\n",
    "\n",
    "# 2) Create a single DataFrame that holds:\n",
    "#    - file_path (string)\n",
    "#    - label (numeric, after encoding)\n",
    "#    - sample_weight (float)\n",
    "df_train = X_train.copy()  # X_train has file_path, sample_weight, etc.\n",
    "df_train['label'] = y_train_encoded.astype(np.int32)   # or int\n",
    "df_train['sample_weight'] = df_train['sample_weight'].astype(np.float32)\n",
    "\n",
    "# (Optional) remove columns you don't need, e.g. 'ddi_scale' or anything else:\n",
    "if 'ddi_scale' in df_train.columns:\n",
    "    df_train.drop('ddi_scale', axis=1, inplace=True)\n",
    "\n",
    "# 3) Identify underrepresented classes in *numeric* form\n",
    "#    underrepresented_classes is currently a list of strings\n",
    "#    We transform them to their numeric code\n",
    "underrepresented_classes_encoded = label_encoder.transform(underrepresented_classes)\n",
    "underrepresented_classes_encoded = set(underrepresented_classes_encoded)  # for quick \"in\" checks\n",
    "\n",
    "print(\"Underrepresented classes (string):\", underrepresented_classes)\n",
    "print(\"Underrepresented classes (encoded):\", underrepresented_classes_encoded)\n",
    "\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_train['label'])\n",
    "print(df_train['sample_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline augmentation for all classes\n",
    "baseline_aug_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,       # mild rotation\n",
    "    width_shift_range=0.05,  # mild shift\n",
    "    height_shift_range=0.05,\n",
    "    # Add more if desired, e.g. brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "# Extra augmentation for underrepresented classes\n",
    "minority_aug_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,       # heavier rotation\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    # Potentially color transformations, e.g. channel_shift_range=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "def custom_augment_generator(\n",
    "    df,\n",
    "    underrepresented_classes_encoded,\n",
    "    baseline_aug_datagen,\n",
    "    minority_aug_datagen,\n",
    "    base_dir,\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    shuffle=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Yields (X_batch, y_batch, w_batch):\n",
    "      - baseline_aug_datagen for well-represented classes\n",
    "      - minority_aug_datagen for underrepresented classes\n",
    "      - with sample weights in w_batch\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            df = df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        for start in range(0, len(df), batch_size):\n",
    "            batch_df = df.iloc[start:start+batch_size]\n",
    "            \n",
    "            images = []\n",
    "            labels = []\n",
    "            weights = []\n",
    "            \n",
    "            for _, row in batch_df.iterrows():\n",
    "                # 1) Build full path\n",
    "                full_path = os.path.join(base_dir, row['file_path'])\n",
    "                \n",
    "                # 2) Read image (BGR)\n",
    "                img_bgr = cv2.imread(full_path)\n",
    "                if img_bgr is None:\n",
    "                    # File missing or corrupted, skip\n",
    "                    continue\n",
    "                \n",
    "                # 3) Convert to RGB\n",
    "                img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "                CapsNets \n",
    "                # 4) Resize\n",
    "                img_rgb = cv2.resize(img_rgb, target_size)\n",
    "                \n",
    "                # 5) Force float32 BEFORE augmentation\n",
    "                img_rgb = img_rgb.astype(np.float32)\n",
    "                \n",
    "                # 6) Decide which datagen to use\n",
    "                if row['label'] in underrepresented_classes_encoded:\n",
    "                    # heavier augmentation\n",
    "                    img_aug = minority_aug_datagen.random_transform(img_rgb)\n",
    "                    img_aug = minority_aug_datagen.standardize(img_aug)\n",
    "                else:\n",
    "                    # baseline augmentation\n",
    "                    img_aug = baseline_aug_datagen.random_transform(img_rgb)\n",
    "                    img_aug = baseline_aug_datagen.standardize(img_aug)\n",
    "                \n",
    "                images.append(img_aug)\n",
    "                labels.append(row['label'])\n",
    "                weights.append(row['sample_weight'])\n",
    "            \n",
    "            # Convert lists to numpy arrays\n",
    "            X_batch = np.array(images, dtype=np.float32)\n",
    "            y_batch = np.array(labels, dtype=np.int32)\n",
    "            w_batch = np.array(weights, dtype=np.float32)\n",
    "            \n",
    "            # Yield triple so Keras interprets w_batch as sample weights\n",
    "            yield (X_batch, y_batch, w_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 1) Create the generator\n",
    "train_gen = custom_augment_generator(\n",
    "    df=df_train,\n",
    "    underrepresented_classes_encoded=underrepresented_classes_encoded,\n",
    "    baseline_aug_datagen=baseline_aug_datagen,\n",
    "    minority_aug_datagen=minority_aug_datagen,\n",
    "    base_dir=base_dir,          # e.g. \".../.../bttai-ajl-2025/train/train\"\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 2) Compute steps_per_epoch (No change)\n",
    "steps_per_epoch = math.ceil(len(df_train) / 32)\n",
    "\n",
    "# 3) Build the ConvNeXt-Tiny model\n",
    "base_model = ConvNeXtTiny(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers (optional)\n",
    "base_model.trainable = False  # Set to True if fine-tuning\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Pooling layer to reduce dimensions\n",
    "num_classes = len(label_encoder.classes_)  # Number of output classes\n",
    "\n",
    "# Add the classification head\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Create the full model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 4) Compile the model (AdamW optimizer for stability)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"best_model.h5\", monitor=\"val_loss\", save_best_only=True)\n",
    "]\n",
    "\n",
    "# 5) Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Fine-tuning\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# Lower learning rate for making smaller adjustments\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 1) After training finishes\n",
    "model.save(\"my_model.h5\")\n",
    "\n",
    "print(\"‚úÖ Model saved as my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model(\"my_model.h5\")\n",
    "# print(\"‚úÖ Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Suppose we have a fitted label_encoder\n",
    "# # label_encoder.classes_ is an array like ['basal-cell-carcinoma', 'melanoma', ...]\n",
    "# idx_to_label = {i: label for i, label in enumerate(label_encoder.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# predictions = []\n",
    "\n",
    "# # The base_test_dir you mentioned:\n",
    "# test_images_dir = base_test_dir  # e.g. \"/kaggle/input/bttai-ajl-2025/test/test\"\n",
    "\n",
    "# for idx, row in test_df.iterrows():\n",
    "#     md5_name = row[\"md5hash\"]  # e.g. something.jpg\n",
    "#     img_path = os.path.join(test_images_dir, md5_name)\n",
    "\n",
    "#     if os.path.exists(img_path):\n",
    "#         # Load and preprocess the image\n",
    "#         image = load_img(img_path, target_size=(224, 224))\n",
    "#         img_array = img_to_array(image)\n",
    "#         img_array = img_array / 255.0  # Normalize to [0,1]\n",
    "#         img_array = np.expand_dims(img_array, axis=0)  # shape (1,224,224,3)\n",
    "\n",
    "#         # Model prediction\n",
    "#         pred = model.predict(img_array)  # shape (1, num_classes)\n",
    "#         pred_idx = np.argmax(pred[0])    # integer index\n",
    "#         predicted_label = idx_to_label.get(pred_idx, \"unknown\")\n",
    "#     else:\n",
    "#         predicted_label = \"unknown\"\n",
    "\n",
    "#     predictions.append(predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[\"md5hash\"] = test_df[\"md5hash\"].str.replace(\".jpg\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_df = pd.DataFrame({\n",
    "#     \"md5hash\": test_df[\"md5hash\"],\n",
    "#     \"label\": predictions\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# submission_file_path = \"submission.csv\"\n",
    "# submission_df.to_csv(submission_file_path, index=False)\n",
    "# print(f\"‚úÖ Submission file saved: {submission_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
