{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter Code for Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,BatchNormalization,Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "from tensorflow import data as tf_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_directory = \"../bttai-ajl-2025/test/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Images: \", len(os.listdir(img_directory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_skipped = 0\n",
    "# Initialize a counter to keep track of the number of corrupted images that are skipped.\n",
    "\n",
    "for fname in os.listdir(img_directory):\n",
    "    # Loop through each file name in the current folder.\n",
    "\n",
    "    fpath = os.path.join(img_directory, fname)\n",
    "    # Construct the full file path by joining the folder path with the file name.\n",
    "\n",
    "    try:\n",
    "        fobj = open(fpath, \"rb\")\n",
    "        # Open the file in binary read mode, which decodes the image into bytes (0,1).\n",
    "\n",
    "        is_jfif = b\"JFIF\" in fobj.peek(10)\n",
    "        # Check if the first 10 bytes of the file contain the \"JFIF\" marker, indicating a valid JPEG file.\n",
    "\n",
    "    finally:\n",
    "        fobj.close()\n",
    "        # Ensure the file is closed after checking, whether or not an exception occurs.\n",
    "\n",
    "    if not is_jfif:\n",
    "        # If the file is not a valid JPEG (does not contain the JFIF marker):\n",
    "\n",
    "        num_skipped += 1\n",
    "        # Increment the counter for skipped (corrupted) images.\n",
    "\n",
    "        os.remove(fpath)\n",
    "        # Delete the corrupted image file from the directory.\n",
    "\n",
    "print(f\"Deleted {num_skipped} images.\")\n",
    "# Print the total number of corrupted images that were deleted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(directory):\n",
    "    \"\"\"\n",
    "    Extracts image dimensions and pixel channel values from images in the given directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing image files.\n",
    "\n",
    "    Returns:\n",
    "        dimensions (list): A list of tuples containing image dimensions and channel count (width, height, channels).\n",
    "        channel_values (numpy.ndarray): A flattened array of RGB pixel values from all images.\n",
    "    \"\"\"\n",
    "    dimensions = []  # List to store image dimensions\n",
    "    channel_values = []  # List to store pixel values for RGB images\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:  # Iterate over each file\n",
    "            # Check if the file is a JPEG\n",
    "            if file.lower().endswith('.jpg') or file.lower().endswith('.jpeg'):\n",
    "                file_path = os.path.join(root, file)  # Get the full file path\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:  # Open the image file\n",
    "                        width, height = img.size  # Get the width and height of the image\n",
    "                        channels = len(img.getbands())  # Get the number of color channels\n",
    "                        dimensions.append((width, height, channels))  # Append dimensions to the list\n",
    "\n",
    "                        # Collect pixel values if the image has RGB channels\n",
    "                        if channels == 3:\n",
    "                            pixels = np.array(img)  # Convert image to a NumPy array\n",
    "                            channel_values.append(pixels.reshape(-1, 3))  # Flatten and append pixel values\n",
    "                except Exception as e:\n",
    "                    # Print an error message if the file cannot be processed\n",
    "                    print(f\"Could not process file {file_path}: {e}\")\n",
    "\n",
    "    # Combine all channel values into a single array if any RGB images exist\n",
    "    if channel_values:\n",
    "        channel_values = np.concatenate(channel_values, axis=0)\n",
    "\n",
    "    return dimensions, channel_values  # Return the dimensions and pixel values\n",
    "    # Remember that dimentions and channel values are both lists; they need to be accessed accordingly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the distribution of dimensions and channel values\n",
    "def plot_distributions(dimensions, channel_values):\n",
    "    widths = [dim[0] for dim in dimensions]  # Extract image widths\n",
    "    heights = [dim[1] for dim in dimensions]  # Extract image heights\n",
    "    channels = [dim[2] for dim in dimensions]  # Extract channel counts\n",
    "\n",
    "    # Create a figure for plotting\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Plot the distribution of widths and heights\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(widths, bins=30, alpha=0.7, label='Widths')  # Histogram for widths\n",
    "    plt.hist(heights, bins=30, alpha=0.7, label='Heights')  # Histogram for heights\n",
    "    plt.title('Width and Height Distribution')  # Title for the plot\n",
    "    plt.xlabel('Pixels')  # X-axis label\n",
    "    plt.ylabel('Frequency')  # Y-axis label\n",
    "    plt.legend()  # Add a legend\n",
    "\n",
    "    # Plot the distribution of channel counts\n",
    "    plt.subplot(2, 2, 2)\n",
    "    channel_counts = Counter(channels)  # Count occurrences of each channel count\n",
    "    plt.bar(channel_counts.keys(), channel_counts.values(), color='orange', alpha=0.7)  # Bar chart for channel counts\n",
    "    plt.title('Channel Count Distribution')  # Title for the plot\n",
    "    plt.xlabel('Number of Channels')  # X-axis label\n",
    "    plt.ylabel('Frequency')  # Y-axis label\n",
    "\n",
    "    # Plot the distribution of RGB channel values if available\n",
    "    if channel_values.size > 0:\n",
    "        plt.subplot(2, 1, 2)\n",
    "        colors = ['Red', 'Green', 'Blue']  # Define color labels\n",
    "        for i, color in enumerate(colors):  # Iterate over each channel\n",
    "            plt.hist(channel_values[:, i], bins=50, alpha=0.7, label=f'{color} Channel', color=color.lower())  # Histogram for each channel\n",
    "        plt.title('RGB Channel Value Distribution')  # Title for the plot\n",
    "        plt.xlabel('Pixel Value')  # X-axis label\n",
    "        plt.ylabel('Frequency')  # Y-axis label\n",
    "        plt.legend()  # Add a legend\n",
    "\n",
    "    # Adjust layout for better readability\n",
    "    plt.tight_layout()\n",
    "    plt.show()  # Display the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims, channel_val = get_image_data(img_directory)\n",
    "plot_distributions(dims, channel_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [os.path.join(img_directory, fname) for fname in os.listdir(img_directory) if fname.lower().endswith(('.jpg', '.jpeg'))]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_files)\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [256, 256])  # Resize to the desired size\n",
    "    return img\n",
    "\n",
    "# Map the load function to the dataset\n",
    "dataset = dataset.map(load_and_preprocess_image)\n",
    "\n",
    "# Batch the dataset\n",
    "dataset = dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_batch(dataset, num_images=25):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Iterate through the dataset\n",
    "    for images in dataset.take(1):  # Take one batch\n",
    "        for i in range(num_images):\n",
    "            ax = plt.subplot(5, 5, i + 1)  # Create a 3x3 grid\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))  # Convert tensor to numpy array\n",
    "            plt.axis(\"off\")  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to display images\n",
    "display_batch(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
